\SweaveOpts{engine=R}
\SweaveOpts{prefix.string=charts/lossDev}
% \VignetteIndexEntry{Using lossDev}
% \VignetteDepends{rjags}
% \VignetteKeywords{lossDev}
% \VignettePackage{lossDev}

% The following commands were taken from the vignette for quantreg
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\Rmethod}[1]{{\textit{#1}}}
\newcommand{\Rfunarg}[1]{{\textit{#1}}}
\newcommand{\R}{{\normalfont\textsf{R}}{}}
\renewcommand{\S}{{\normalfont\textsf{S}}{}}
% end commands taken from quantreg

\documentclass[a4paper]{article}
\usepackage{a4wide}
\usepackage{graphicx}
\setlength{\parskip}{0.7ex plus0.1ex minus0.1ex}
\setlength{\parindent}{0em}


\newcommand{\lossDevVersion}{0.7.0}
\newcommand{\lossDev}{\Rpackage{lossDev}}
\newcommand{\JAGS}{JAGS}


\usepackage{subfigure}
\usepackage{float}
\usepackage{hyperref}

\restylefloat{figure}

\title{Robust Loss Development Using MCMC: A Vignette}
\author{Christopher W. Laws \and Frank A. Schmid}

\begin{document}
\setkeys{Gin}{width=.85\textwidth}
\renewcommand{\topfraction}{.9}
\renewcommand{\bottomfraction}{.9}
\renewcommand{\textfraction}{.1}
\maketitle


\begin{abstract}
  For many lines of insurance, the ultimate loss associated with a
  particular exposure (accident or policy) year may not be realized
  (and hence known) for many calendar years; instead these losses
  develop as time progresses .  The actuarial concept of loss
  development aims at estimating (at the level of the aggregate loss
  triangle) the ultimate losses for the exposure years, given their
  respective stages of maturity (as defined by the time distance
  between the exposure year and the latest observed calendar year.
  Traditional actuarial methods arrive at such estimates often
  mechanistically, without due modeling of the underlying
  data-generating process.  This vignette describes and demonstrates
  the use of the package lossDev, which centers on a Bayesian time
  series model of loss development.  Notable features of this model
  are a skewed Student-\emph{t} distribution with time-varying scale
  and skewness parameters, the use of an expert prior for the calendar
  year effect, and the ability to accommodate a structural break in
  the consumption path of services.  \R{} and the package are
  open-source software projects and can be freely downloaded from
  CRAN: \url{http://cran.r-project.org} and
  \url{http://lossdev.r-forge.r-project.org/}.
\end{abstract}


\section{Installation}
At the time of writing this vignette the current version of \lossDev{}
is \lossDevVersion{}.  \lossDev{} is released as an \R{} package and
can be downloaded from \url{http://lossdev.r-forge.r-project.org/}.
\lossDev{} should be available on CRAN shortly.  (For instructions on
installing \R{} packages please see the help files for \R{}.)
\lossDev{} requires \Rpackage{rjags} for
installation. \Rpackage{rjags} requires that a valid version of
\JAGS{} be installed on the system.  \JAGS{} is an open source program
for analysis of Bayesian hierarchical models using Markov Chain Monte
Carlo (MCMC) simulation and can be freely download from
\url{http://calvin.iarc.fr/~martyn/software/jags/}.

\section{Model Overview}

\lossDev{} splits the data-generating process of the loss triangle
into three time dimensions, which are exposure growth, the calendar
year effect, and the run-off, thus resulting into a time series model
with three dimensions.  Specifically, the incremental payments are
driven by three time processes, which manifest themselves in exposure
growth, development, and the calendar year effect; these processes are
illustrated in Figure~\ref{fig:TriangleDynamics}.

\begin{figure}[h]
  \centering
  \includegraphics{3TimeDimensions.jpg}
  \caption{Triangle Dynamics.}
  \label{fig:TriangleDynamics}
\end{figure}

In the model, the growth rate that represents the calendar year effect
is denoted $\kappa$.  The rate of exposure growth, $\eta$, is net of
the calendar year effect.  The growth rate $\delta$ is the rate of
decay in incremental payments, adjusted for the calendar year effect.
Incremental payments that have been adjusted for the calendar year
effect (and, hence, inflation) represent consumption of units of
services; for instance, for an auto bodily injury triangle, this
consumption pertains to medical services.  A decline in consumption at
the level of the aggregate loss triangle may be due to claimants
exiting or remaining claimants decreasing their consumption.

For a more detailed explanation, including model equations, please see \\
Schmid, Frank A. ``Robust Loss Development Using MCMC,'' 2009.


\lossDev{} currently provides two models.  Both of which are designed
to develop losses for annual insurance data.

Section~\ref{sec:UsingtheStandardModelforEstimation} uses the first
model, which assumes that all exposure years are subject to a
common consumption path, to develop an example loss triangle.
.

Section~\ref{sec:UsingtheBreakModelforEstimation} uses the second
model to develop another loss triangle.  The second model allows for a
structural break in the consumption path and assumes earlier exposure
years are subject to one consumption path and later exposure years are
subject to another.





\section{Using the Standard Model for Estimation}
\label{sec:UsingtheStandardModelforEstimation}
\subsection{Data}
For a demonstration of the standard (break-less) model an example loss
triangle is taken from an Automatic Facilitative business in General
Liability (excluding Asbestos \& Environmental).  The payments are on
an incurred basis.

This triangle is take from \\
Mack, Thomas, ``Which
Stochastic Model is Underlying the Chain Ladder Method,'' \textit{Casualty
Actuarial Society Forum}, Fall 1995, pp. 229-240,
\url{http://www.casact.org/pubs/forum/95fforum/95ff229.pdf}.


\subsection{Model Specification}
Standard models are specified with the function
\Rfunction{makeStandardAnnualInput}.  This function takes as input all
data used in the estimation process.
\Rfunction{makeStandardAnnualInput} also allows the user to vary the
model specification through several arguments.  Most of these
arguments have defaults which should be suitable for most purposes.

To ensure portability, the data used in this vignette is packaged in
\lossDev{} and as such is loaded using the \Rfunction{data}
function. However, the user wishing to develop other loss triangles
should load the data using standard R functions (such as
\Rfunction{read.table} or \Rfunction{read.csv}).  See the \R{} manual
for assistance.

\subsubsection{Loading and Manipulating  the Data}
\label{sec:standardModelData}
\paragraph{The Triangle}
As input, \Rfunction{makeStandardAnnualInput} can take either a
cumulative loss triangle or an incremental loss triangle (or in the
case where one might not be directly calculable from the other, both
triangles may be supplied).  \Rfunction{makeStandardAnnualInput}
expects any supplied loss triangle to be a matrix.  The row names for
the matrix must be the Accident (or Policy) Year and must appear in
ascending order.  The matrix must be square and \emph{all} values
below the diagonal must be missing. Missing values on and above the
diagonal are permitted.

Note the negative value for this example in Accident Year 1982.  Since
incremental payments are modeled on the log scale, this value will be
treated as missing and could result in a slightly overstated ultimate
loss.  A comparison of predicted vs observed cumulative payments in
Figure~\ref{fig:standardfinalCumulativeDiff} indicates that, at least
in this instance, this has a minimal effect.

<<setValueSoUsersCanLookAtAllPlots,echo=FALSE>>=
options(device.ask.default=TRUE)
@



<<LoadTriangleForStandardModel>>=
library(lossDev) #load the library

## load the triangle, "data" loads the triangle as a data.frame so it must be coerced into a matrix
data(IncrementalGeneralLiablityTriangle)
IncrementalGeneralLiablityTriangle <- as.matrix(IncrementalGeneralLiablityTriangle)
#print(IncrementalGeneralLiablityTriangle[(-5:0) + dim(IncrementalGeneralLiablityTriangle)[1], 1:6])
print(IncrementalGeneralLiablityTriangle)

@
\paragraph{The Stochastic Inflation Proxy}
It is possible that incremental payments are subject to price
increases due to external forces such as inflation.
\Rfunction{makeStandardAnnualInput} can take such forces into account
by suppling a rate of inflation from an inflationary index such as the
CPI to be used as a proxy for the true value.  The supplied rate of
inflation must cover the years of the supplied incremental triangle
and extend (both into the past and future) beyond these years.  If a
future year's rate of inflation is needed and is unobserved, it will
be simulated from an Ornstein--Uhlenbeck process calibrated to the
observed series.

For this example, the CPI is taken as a prior or the stochastic rate of inflation.

Note that rates of inflation beyond the last observed diagonal in
\Robject{IncrementalGeneralLiablityTriangle} are excluded from this
example.  While \lossDev{} is capable of utilizing such information
beyond the last observed diagonal, to make the example more realistic
the series has been truncated.

<<LoadCPIForStandardModel>>=
## load the stochastic inflation series, "data" loads the series as a data.frame so it must be coerced into a vector
data(CPI)
CPI <- as.matrix(CPI)[,1]
CPI.rate <- CPI[-1] / CPI[-length(CPI)] - 1
CPI.rate.length <- length(CPI.rate)
print(CPI.rate[(-10):0 + CPI.rate.length])

##restrict the cpi to only those years available when the triangle created
CPI.years <- as.integer(names(CPI.rate))
years.available <- CPI.years <= max(as.integer(dimnames(IncrementalGeneralLiablityTriangle)[[1]]))

CPI.rate <- CPI.rate[years.available]
CPI.rate.length <- length(CPI.rate)
print(CPI.rate[(-10):0 + CPI.rate.length])

@
\subsubsection{Selection of Model Options}
\label{sec:standardSelectionOfModelOptions}
The function \Rfunction{makeStandardAnnualInput} has many options to
allow for customization of model specification; however, in an aim to
avoid overwhelming the reader, not all options will be illustrated by
this tutorial.

For this example, the loss history is supplied as incremental payments
to the argument \Robject{incremental.payments}.   The exposure year
type of this triangle is also set to Accident Year by setting the
value of \Robject{exp.year.type} to ``ay.''  The default is
``ambiguous'' which should be sufficient in most cases as this
information is only utilized by a handful of functions and the
information can be supplied (or overridden at the execution time of
those function).

The function allows for the specification of two rates of inflation
(plus a zero rate of inflation).  One of these rates is allowed to be
stochastic meaning that uncertainty in future rates of this inflation
series are simulated from a process calibrated by the observed
series. For the current demonstration, it will be assumed that the CPI
is the only applicable inflation rate.  As only historical values for
the CPI are known, the CPI is assumed to be a stochastic rate of
inflation.  This is done by setting the value of
\Robject{stoch.inflation.rate} to \Robject{CPI.rate} (which was
created earlier).  The user has the option of specifying what
percentage (with this value being allowed to vary for each cell) of
dollars inflate at \Robject{stoch.inflation.rate}. For the current
illustration, it is assumed that all dollars (in all periods) follow
the CPI. This is done by setting \Robject{stoch.inflation.weight} to 1
and \Robject{non.stoch.inflation.weight} to 0.

By default, the measurement equation for the logarithm of the
incremental payments is a Student-\textit{t}.  The user has the option
of using a skewed-\textit{t} by setting the value of
\Robject{use.skew.t} to TRUE.  For this demonstration, a
skewed-\textit{t} will be used.

Since \lossDev{} is designed to develop loss triangles to ultimate,
some assumptions must be made with regard to the extension of the
consumption path beyond the number of development years in the
observed triangle.  The default assumes the last estimated decay rate
is applicable for all future development years and is assumed for this
example.  This default can be overridden by the argument
\Robject{projected.rate.of.decay}.  Additionally, either the final
number of (possibly) non-zero payments must be supplied via the
argument \Robject{total.dev.years} or the number of non-zero payments
in addition to the number of development years in the observed
triangle must be supplied via the argument \Robject{extra.dev.years}.
Similarly, the number additional of exposure years can also be
specified.



<<CreateTheStandardModelInputObject>>=
standard.model.input <- makeStandardAnnualInput(incremental.payments = IncrementalGeneralLiablityTriangle,
                                                stoch.inflation.weight = 1,
                                                non.stoch.inflation.weight = 0,
                                                stoch.inflation.rate = CPI.rate,
                                                exp.year.type = 'ay',
                                                extra.dev.years=5,
                                                use.skew.t=TRUE)


@
\subsection{Estimating the Model}
\label{sec:estimatingTheStandardModel}
Once the model has been specified, it must be estimated.

\paragraph{MCMC Overview}
As the model is Bayesian, the model is estimated by means of Markov
chain Monte Carlo Simulation (MCMC).  To perform MCMC, a Markov chain
is constructed in such a way that the limiting distribution of the
chain is the posterior distribution of interest.  The chain is then
initialized with starting values and run until it has reached a point
of convergence in which samples adequately represent random (albeit
sequentially dependent) draws from this posterior distribution. The set
of iterations performed (and discarded) until samples are assumed to
be draws from the posterior is called a ``burn-in.'' Once the chain has
converged, the chain is iterated further to collect samples.  The
samples are then used to calculated the statistic of interest.

While the user is not responsible for the construction of the Markov
chain, he is responsible for assessing the chains convergence.
(Section~\ref{sec:standardAssessingConvergence} gives some pointers on
this.)  The most common way of accomplishing this task is by running
several chains simultaneously with each chain started with a different
set of initial values.  Once all the chains are producing similar
results, one can assume the chains have converged.

To estimate the model, the function \Rfunction{runLossDevModel} is
called with the first argument being the input object created by
\Rfunction{makeStandardAnnualInput}. To specify the number of
iterations to discard, the user sets the value of \Robject{burnIn}.
To specify the number of iterations to perform after the burn-in, set
the value of \Robject{sampleSize}.  To set the number of chains to run
simultaneously, supply a value for \Robject{nChains}.  The default
value for \Robject{nChains} is 3 and should be sufficient for most
cases.

It is also common practice (due to the autocorrelation in MCMC
samples) to ``thin'' the samples.  This simply means that only every
n-th draw is stored.  The argument \Robject{thin} is available for
this purpose.

\paragraph{Memory Issues}
MCMC can require large amounts of memory.  To allow \lossDev{} to work
with limited hardware, the \R{} package \Rpackage{filehash} is used to
cache the codas of monitored values to the hard-drive in an efficient
way. While such caching can allow estimation of large triangles on
computers with less memory, it can also slow down some computations.
As such, the user has the option of turning this feature on and off.
This is done via the function \Rfunction{lossDevOptions} by setting
the argument \Robject{keepCodaOnDisk} to FALSE.

\R{} also makes available the function \Rfunction{memory.limit} which
one may find useful.


<<EstiamteTheStandardModel>>=
standard.model.output <- runLossDevModel(standard.model.input,
                                         burnIn=30.0E+3,
                                         sampleSize=40.0E+3,
                                         thin=10)



@


\subsection{Examining Output}
\Rfunction{makeStandardAnnualInput} returns a very complex output object.
\lossDev{} provides many user-level functions to access the information
contained in this object.  Many of these functions are described below.

\subsubsection{Assessing Convergence}
\label{sec:standardAssessingConvergence}
As previously mentioned, the user is responsible for assessment of the
convergence of the Markov Chains used to estimate the model. To this
aim, \lossDev{} provides several functions to produce trace and
density plots.

Arguably, the most important charts to examine for convergence are the
trace plots associated with the three time dimensions of the
model. Convergence of exposure growth, the consumption path, and the
calendar year effect are assessed in
Figures~\ref{fig:standardEtaTracePlot},
\ref{fig:standardConsumptionPathTracePlot}, and
\ref{fig:standardCalendarYearErrorTracePlot} respectively.  These
charts are produced with the functions
\Rfunction{exposureGrowthTracePlot},
\Rfunction{consumptionPathTracePlot}, and
\Rfunction{calendarYearEffectErrorTracePlot}.

\begin{figure}[h]
  \centering

<<plotStandardexposureGrowthTrace, fig=T, height=7, width=14>>=
exposureGrowthTracePlot(standard.model.output)

@
\caption{Trace plots for select exposure growth parameters.}
\label{fig:standardEtaTracePlot}
\end{figure}

\begin{figure}[h]
  \centering

<<plotStandardConsumptionPathTrace, fig=T, height=7, width=14>>=
consumptionPathTracePlot(standard.model.output)

@
\caption{Trace plots for select development years on the consumption path.}
\label{fig:standardConsumptionPathTracePlot}
\end{figure}

\begin{figure}[h]
  \centering

<<plotStandardConsumptionPathTrace, fig=T, height=7, width=14>>=
calendarYearEffectErrorTracePlot(standard.model.output)

@
\caption{Trace plots for select calendar year effect errors.}
\label{fig:standardCalendarYearErrorTracePlot}
\end{figure}


\subsubsection{Assessing Model Fit}
\label{sec:standardAssesingModelFit}
\lossDev{} provides many diagnostic charts to asses how well the model
fits the observed triangle.

\paragraph{Residuals}
For analysis of residuals, \lossDev{} provides the function
\Rfunction{triResi}. \Rfunction{triResi} plots the residuals (on the
log scale) by the three time dimensions.  The time dimension is
selected by means of the argument \Robject{timeAxis}.  By default
residual charts are standardized to account for any assumed/estimated
heteroskedasticity in the payments.  These charts can be found in
Figures~\ref{fig:stanResiDevYear}, \ref{fig:stanResiExpYear}, and
\ref{fig:stanResiCalYear}.

Note that because incremental payments are assumed to be skewed, the
residuals need not be symmetric.

\begin{figure}[h]
  \centering

<<standardResiByDevYear, fig=T, height=7, width=14>>=
triResi(standard.model.output, timeAxis='dy')

@
\caption{Residuals by development year.}
\label{fig:stanResiDevYear}
\end{figure}

\begin{figure}[h]
  \centering

<<standardResiByExpYear, fig=T, height=7, width=14>>=
triResi(standard.model.output, timeAxis='ey')

@
\caption{Residuals by exposure year.}
\label{fig:stanResiExpYear}
\end{figure}

\begin{figure}[h]
  \centering

<<standardResiByCalYear, fig=T, height=7, width=14>>=
triResi(standard.model.output, timeAxis='cy')

@
\caption{Residuals by calendar year.}
\label{fig:stanResiCalYear}
\end{figure}

\paragraph{QQ-Plot}
\lossDev{} provides a QQ-Plot in the function \Rfunction{QQPlot}.
\Rfunction{QQPlot} plots the median of simulated incremental payments
(sorted at each simulation) against the observed incremental payments.
Plotted points from a well calibrated model will be close to the
45-degree line.  These results are shown in Figure~\ref{fig:standardQQ}.

\begin{figure}[h]
  \centering

<<standardQQ, fig=T, height=7, width=14>>=
QQPlot(standard.model.output)

@
\caption{QQ-Plot.}
\label{fig:standardQQ}
\end{figure}

\paragraph{Comparison of Cumulative Payments}
As a means of assessing how well the predicted cumulative payments line
up with the observed values, \lossDev{} provides the function
\Rfunction{finalCumulativeDiff}.  This function will plot the relative
difference between the predicted and observed cumulative payments
(when such payments exists) for the last observed cumulative payment
in each exposure year.  Credible intervals are also plotted. These
results are shown in Figure~\ref{fig:standardfinalCumulativeDiff} and
can be useful for assessing the impact of negative incremental
payments as previously stated.

\begin{figure}[h]
  \centering

<<standardfinalCumulativeDiff, fig=T, height=7, width=14>>=
finalCumulativeDiff(standard.model.output)

@
\caption{Difference in Final Observed Cumulative Payments.}
\label{fig:standardfinalCumulativeDiff}
\end{figure}



\subsubsection{Extracting Inference and Results}
\label{sec:standardExtractingInferenceandResults}
Once the user has deemed the Markov chains converged and once the user
has determined that the model has (at least reasonably) captured the
underly process observed in the triangle, he will wish to extract
results from the output.  Many of the functions mentioned in this
section also return the values of some plotted information.  These
values are returned invisibly and as such are not printed at the REPL
unless such an operation is requested. Additionally, many of these
functions also provide an option to suppress plotting.


\paragraph{Predicted Payments}
Perhaps the most practically useful function is
\Rfunction{predictedPayments}.  This function can plot and return the
estimated incremental predicated payments.  As the function can also
plot the observed values against the predicted values
(\Robject{plotObservedValues}), it is also somewhat of a diagnostic
function.  The log incremental payments are plotted against the
predicted values in Figure~\ref{fig:standardPredictedInc}.

\begin{figure}[h]
  \centering

<<standardPredictedInc, fig=T, height=7, width=14>>=
predictedPayments(standard.model.output,
                  type='incremental',
                  logScale=TRUE)
@
\caption{Predicted Incremental Payments.}
\label{fig:standardPredictedInc}
\end{figure}


\Rfunction{predictedPayments} can also plot and return the estimated
cumulative payments and has the option of taking observed payments at
``face value'' (meaning that predicted payments are replaced with
observed payments whenever possible) in the returned calculations;
this can be useful for construction of reserve estimates.  In
Figure~\ref{fig:standardPredictedCumul}, only the predicted cumulative
payments are plotted.  The function is also used to construct an
estimate (with credible intervals) of the ultimate loss.


<<standardPredictedCumul, fig=F>>=
standard.ult <- predictedPayments(standard.model.output,
                                  type='cumulative',
                                  plotObservedValues=FALSE,
                                  mergePredictedWithObserved=TRUE,
                                  logScale=TRUE,
                                  quantiles=c(0.025, 0.5, 0.0975),
                                  plot=FALSE)
standard.ult <- standard.ult[,,dim(standard.ult)[3]]
print(standard.ult)

@

\begin{figure}[h]
  \centering

<<standardPredictedCumul, fig=T, height=7, width=14>>=
predictedPayments(standard.model.output,
                  type='cumulative',
                  plotObservedValues=FALSE,
                  logScale=TRUE)

@
\caption{Predicted Cumulative Payments.}
\label{fig:standardPredictedCumul}
\end{figure}

\paragraph{Consumption Path}
\lossDev{} makes the consumption path available via
\Rfunction{consumptionPath}.  The consumption path is the trajectory
of exposure-adjusted and calendar year effect adjusted log incremental
payments and is modeled as a linear spline.  The standard model
assumes a common consumption path for all exposure years in the
triangle.  The use of this function is demonstrated in
Figure~\ref{fig:standardConsumptionPath}.

\begin{figure}[h]
  \centering

<<standardConsumptionPath, fig=T, height=7, width=14>>=
consumptionPath(standard.model.output)


@
\caption{Consumption Path.}
\label{fig:standardConsumptionPath}
\end{figure}

\paragraph{Knots in the Consumption Path}
As previously mentioned, the consumption path is modeled as a linear
spline.  The number of knots in this spline is endogenous to the
model.  The function \Rfunction{numberOfKnots} can be used to extract
information regarding the posterior number of knots.  All else equal,
a higher number of knots indicates a higher degree of non-linearity.
Figure~\ref{fig:standardNumberOfKnots} illustrates the use of this
function.

\begin{figure}[h]
  \centering

<<standardNumberOfKnots, fig=T, height=7, width=14>>=
numberOfKnots(standard.model.output)


@
\caption{Number of Knots.}
\label{fig:standardNumberOfKnots}
\end{figure}

\paragraph{Rate of Decay}
While the consumption path illustrates the level of exposure-adjusted
and calendar year effect adjusted log incremental payments, sometimes
one may prefer to examine the development time force in terms of a
decay rate. The rate of decay from one development year to the next
(which is approximately the slope of the consumption path) is made
available via the function \Rfunction{rateOfDecay}. As the standard
model assumes a common consumption path for all exposure years, the
standard model also has a single decay rate.  An example of this
function can be found in Figure~\ref{fig:standardRateOfDecay}.

\begin{figure}[h]
  \centering

<<standardRateOfDecay, fig=T, height=7, width=14>>=
rateOfDecay(standard.model.output)


@
\caption{Rate Of Decay.}
\label{fig:standardRateOfDecay}
\end{figure}

\paragraph{Exposure Growth}
The consumption path shown in Figure~\ref{fig:standardConsumptionPath}
is exposure-adjusted to the first exposure year.  This path is
renormalized to each exposure year so as to reflect the level of
exposure for that particular year.  The year over year changes in the
estimated exposure level are made available by the function
\Rfunction{exposureGrowth}. An example of this function can be found
in Figure~\ref{fig:standardExposureYearGrowth}.

\begin{figure}[h]
  \centering

<<standardExposureYearGrowth, fig=T, height=7, width=14>>=
exposureGrowth(standard.model.output)


@
\caption{Exposure Growth.}
\label{fig:standardExposureYearGrowth}
\end{figure}

\paragraph{Calendar Year Effect}
The model assumes that every cell on a diagonal receives a related
shock.  The shock consists of a component exogenous to the triangle
(generally an inflationary index such as the CPI or MCPI) and an
endogenous stochastic component.  As \lossDev{} theoretically allows
the user to vary the exogenous component for each cell, graphically
displaying the entire calendar year effect requires three dimensions.
This is done by plotting a grid of colored block and varying the
intensity of each color according to the associated calendar year
effect.  An example of this can be found in
Figure~\ref{fig:standardCalendarYearEffect}.  Note that cell (1,1) is
undefined.

\begin{figure}[h]
  \centering

<<standardCalendarYearEffect, fig=T, height=7, width=14>>=
calendarYearEffect(standard.model.output)


@
\caption{Calendar Year Effect.}
\label{fig:standardCalendarYearEffect}
\end{figure}

Alternatively, one could merely plot the endogenous stochastic
component.  As this is component is common to all cells on a given
diagonal, the number of dimensions is reduced by one.  An illustration
of this isolated component is displayed in
Figure~\ref{fig:standardCalendarYearEffectErrors}.  This example
displays some degree of autocorrelation.  \lossDev{} can account for
such correlation by setting the argument
\Robject{use.ar1.in.calendar.year} in
\Rfunction{makeStandardAnnualInput} to TRUE.  Exploring this is left
as an exercise to the reader.

\begin{figure}[h]
  \centering

<<standardCalendarYearEffectErrors, fig=T, height=7, width=14>>=
calendarYearEffectErrors(standard.model.output)


@
\caption{Calendar Year Effect Errors.}
\label{fig:standardCalendarYearEffectErrors}
\end{figure}


\paragraph{Changes In Variance}
As development time progresses, the number of transactions which
comprise the cells in the incremental triangle declines.  This can
lead not only to a decrease in the level, but also an increase in the
variance associated with each cell.  In order to account for this, the
model (optionally) allows for the scale parameter to vary with
development time.  This scale parameter is smoothed via a second-order
random walk on the log scale.  As a result, the standard deviation can
vary for each development year.  An example is displayed in
Figure~\ref{fig:standardSTDvsDev}.

\begin{figure}[h]
  \centering

<<standardSTDvsDev, fig=T, height=7, width=14>>=
standardDeviationVsDevelopmentTime(standard.model.output)


@
\caption{Standard Deviation vs Development Time.}
\label{fig:standardSTDvsDev}
\end{figure}




\paragraph{Skewness Parameter}
As previously mentioned, the measurement equation for the log
incremental payments is (optionally) a skewed-\emph{t}.
\Rfunction{skewnessParameter} allows for the illustration of the
posterior skewness parameter.  (For reference, the prior is also
illustrated.)  While the skewness parameter does not directly
translate in the estimated skewness, it is related.  For instance, a
skewness parameter of zero would correspond to zero skew.  An example
is displayed in Figure~\ref{fig:standardSkew}.

\begin{figure}[h]
  \centering

<<standardSkew, fig=T, height=7, width=14>>=
skewnessParameter(standard.model.output)


@
\caption{Skewness Parameter.}
\label{fig:standardSkew}
\end{figure}

\paragraph{Degrees of Freedom}
The degrees of freedom associated with the measurement equation is
endogenous to the model estimation.  For numerical stability, when
estimating a skewed-\emph{t}, the degrees of freedom is constrained to
be greater than 4.  Otherwise this value is constrained to be greater
than 2.  All else equal, lower degrees of freedom indicate the
presence of fat tails.

The \lossDev{} function \Rfunction{degreesOfFreedom} allows for the illustration of the
posterior degrees of freedom.  (For reference, the prior is also
illustrated.) Figure~\ref{fig:standardSkew} displays the posterior
degrees of freedom for this example.

\begin{figure}[h]
  \centering

<<standardDegreesOfFreedom, fig=T, height=7, width=14>>=
degreesOfFreedom(standard.model.output)


@
\caption{Degrees Of Freedom.}
\label{fig:standardDegreesOfFreedom}
\end{figure}

\subsubsection{The Ornstein--Uhlenbeck Process}
As previously mentioned, future values for the assumed stochastic rate
of inflation are simulated from an Ornstein--Uhlenbeck process.
\lossDev{} allows the user to examine predicted and forecast values as
well as some of the underlying parameters.  Such options are outlined
below.

\paragraph{Fit and Forecast}
To display the fitted values vs the observed values, as well as the
forecast values, the user must use the function
\Rfunction{stochasticInflation}.  The chart for the example
illustrated above is displayed in
Figure~\ref{fig:standardStochInflation}.

\begin{figure}[h]
  \centering

<<standardStochInflation, fig=T, height=7, width=14>>=
stochasticInflation(standard.model.output)


@
\caption{Stochastic Inflation Fit.}
\label{fig:standardStochInflation}
\end{figure}

\paragraph{Stationary Mean}
The Ornstein--Uhlenbeck process has a stationary mean to which
temporary disturbances are assumed to dissipate toward. In other words,
the projected rate of inflation will (geometrically) approach a value
as time progresses.  This stationary mean can be graphed with the
function \Rfunction{StochasticInflationStationaryMean}.  The chart for
the example illustrated above is displayed in
Figure~\ref{fig:standardStochInflationStationaryMean}.

\begin{figure}[h]
  \centering

<<standardStochInflationStationaryMean, fig=T, height=7, width=14>>=
stochasticInflationStationaryMean(standard.model.output)


@
\caption{Estimated Stochastic Inflation Stationary Mean.}
\label{fig:standardStochInflationStationaryMean}
\end{figure}

\paragraph{Persistence}
The Ornstein -- Uhlenbeck process assumes that the influence of a
disturbance decays geometrically with time.  The parameter governing
this rate is traditionally referred to as $\rho$. To obtain this
value, call the function \Rfunction{StochasticInflationRhoParameter}.
The chart for the example illustrated above is displayed in
Figure~\ref{fig:standardStochInflationRhoParameter}.

\begin{figure}[h]
  \centering

<<standardStochInflationRhoParameter, fig=T, height=7, width=14>>=
stochasticInflationRhoParameter(standard.model.output)


@
\caption{Estimated Stochastic Inflation Rho Parameter.}
\label{fig:standardStochInflationRhoParameter}
\end{figure}



<<cleanUpWorkSpace,echo=FALSE>>=
rm(list=ls())
@


\section{Using the Change Point Model for Estimation}
\label{sec:UsingtheBreakModelforEstimation}


The standard model outlined in
Section~\ref{sec:UsingtheStandardModelforEstimation} assumes the same
consumption path for all exposure years.  Due to changes in the loss
environment, this may not be appropriate for all loss triangles.  Such
a triangle is outlined below.

\subsection{Data}
The triangle used for this example is a Private Passenger Auto Bodily
Injury Liability triangle and consists of accident year data on a paid basis.

In December 1986, the ability of a judge to dismiss a case was limited
by a judicial decision.  As such, there is (at least the possibility)
of a change in the consumption path at this point in time which makes
this triangle a good example for the change point model.

This triangle is take from \\
Hayne, Roger M., ``Measurement of Reserve Variability,''
\textit{Casualty Actuarial Society Forum}, Fall 2003, pp. 141-172,
\url{http://www.casact.org/pubs/forum/03fforum/03ff141.pdf}.


\subsection{Model Specification}


\subsubsection{Loading and Manipulating  the Data}
\label{sec:breakLoadingtheData}
\paragraph{The Triangle}
Section~\ref{sec:standardModelData} supplied incremental payments as model input.  For
variety, here cumulative payments are supplied.

Note the large number of zero payments.  Since the model will treat
these as missing values (since they are equal to negative infinity on
the log scale), the predicted payments will be overstated.  This issue
is addressed in Section~\ref{sec:accoutingForZeros}.

<<lossTriangleForBreakModel>>=
data(CumulativeAutoBodilyInjuryTriangle)
CumulativeAutoBodilyInjuryTriangle <- as.matrix(CumulativeAutoBodilyInjuryTriangle)
sample.col <- (dim(CumulativeAutoBodilyInjuryTriangle)[2] - 6:0)
print(decumulate(CumulativeAutoBodilyInjuryTriangle)[1:7, sample.col])

@
\paragraph{The Stochastic Inflation Proxy}
The MCPI is chosen as a proxy for the stochastic rate of inflation.
While in Section~\ref{sec:standardModelData} the stochastic inflating
proxy was truncated for realism, here a few extra observed years are
kept for illustration purposes.

<<mcpiForBreakModel>>=

data(MCPI)
MCPI <- as.matrix(MCPI)[,1]
MCPI.rate <- MCPI[-1] / MCPI[-length(MCPI)] - 1
print(MCPI.rate[(-10):0 + length(MCPI.rate)])

MCPI.years <- as.integer(names(MCPI.rate))
max.exp.year <- max(as.integer(dimnames(CumulativeAutoBodilyInjuryTriangle)[[1]]))
years.to.keep <- MCPI.years <=  max.exp.year + 3
MCPI.rate <- MCPI.rate[years.to.keep]

@
\subsubsection{Selection of Model Options}

While \Rfunction{makeStandardAnnualInput}
(Section~\ref{sec:standardSelectionOfModelOptions}) is used to specify
models without a change point, \Rfunction{makeBreakAnnualInput} is
used to specify models with a change point.
\Rfunction{makeBreakAnnualInput} has most of its arguments in common
with \Rfunction{makeStandardAnnualInput} and all these common
arguments carrier their meanings forward.  However,
\Rfunction{makeBreakAnnualInput} adds a few new arguments to specify
the location of the structural break.

Most notably is the argument \Robject{first.year.in.new.regime}
which, as the name suggests, indicates the first year in which the new
consumption path applies.  This argument can be supplied with a
single value, in which case the model will give a hundred percent
probability to this year being the first year in the new regime.
However, this argument can also be supplied with a range of values
and the model will then estimate the first year in the new regime.
Since the possible break occurs in late 1986, the range of years
chosen for this example is 1986 to 1987.

The prior for the first year in the new regime is a discretized beta
distribution.  The user has the option of choosing the parameters for
this prior by setting the argument
\Robject{prior.for.first.year.in.new.regime}.  Here, since the change
was in late 1986, we choose a prior to give more probability to the
latter year.

The argument \Robject{bound.for.skewness.parameter} is also set to 5.
This avoids the MCMC chain from getting ``stuck'' for this particular
example. One should use the function \Rfunction{skewnessParemter}
(Figure~\ref{fig:breakSkew}) to evaluate the need to set this value.  If the user
is experiencing difficulties with the skewed-\textit{t}, he may wish
to use the non-skewed-\textit{t} by ensuring that the argument
\Robject{use.skew.t} is set to FALSE (which is the default).


<<CreatingTheBreakInputObjectl>>=
break.model.input <- makeBreakAnnualInput(cumulative.payments = CumulativeAutoBodilyInjuryTriangle,
                                          stoch.inflation.weight = 1,
                                          non.stoch.inflation.weight = 0,
                                          stoch.inflation.rate = MCPI.rate,
                                          first.year.in.new.regime = c(1986, 1987),
                                          priors.for.first.year.in.new.regime=c(2,1),
                                          exp.year.type = 'ay',
                                          extra.dev.years = 5,
                                          use.skew.t = TRUE,
                                          bound.for.skewness.parameter=5)
@
\subsection{Estimating the Model}
Just like in Section~\ref{sec:estimatingTheStandardModel}, the S4
object returned by \Rfunction{makeBreakAnnualInput} must be supplied
to the function \Rfunction{runLossDevModel} in order to produce
estimates.

<<EstimateTheBreakModel>>=
break.model.output <- runLossDevModel(break.model.input,
                                      burnIn=30.0E+3,
                                      sampleSize=40.0E+3,
                                      thin=10)

@

\subsection{Examining Output}
\subsubsection{Assessing Convergence}
Just as discussed previously, the user must again examine the MCMC
runs for convergence using the same functions mentioned in
Section~\ref{sec:standardAssessingConvergence}.  Here, to avoid
repetition, only a few of the previously illustrated charts will be
discussed below.


Since the change point model has two consumption paths, the method
\Rfunction{consumptionPathTracePlot} for output related to this model
has an additional argument to specify the consumption path. If the
argument \Robject{preBreak} equals TRUE, then the trace for the
consumption path relevant to exposure years prior to the structural
break will be plotted.  Otherwise, the trace for the consumption path
relevant to exposure years after the break will be plotted.

The trace for the pre-break consumption path is plotted in
Figure~\ref{fig:breakConsumptionPathTracePlotPreBreak}.  The trace for
the post-break path is plotted in
Figure~\ref{fig:breakConsumptionPathTracePlotPostBreak}.

\begin{figure}[h]
  \centering
<<plotBreakConsumptionPathTracePreBreak, fig=T, height=7, width=14>>=
consumptionPathTracePlot(break.model.output, preBreak=TRUE)

@
\caption{Trace plots for select development years on the pre-break consumption path.}
\label{fig:breakConsumptionPathTracePlotPreBreak}
\end{figure}

\begin{figure}[h]
  \centering
<<plotBreakConsumptionPathTracePostBreak, fig=T, height=7, width=14>>=
consumptionPathTracePlot(break.model.output, preBreak=FALSE)

@
\caption{Trace plots for select development years on the post-break consumption path.}
\label{fig:breakConsumptionPathTracePlotPostBreak}
\end{figure}


\subsubsection{Assessing Model Fit}
All of the functions mentioned in
Section~\ref{sec:standardAssesingModelFit} are available for the
change point model as well.

\paragraph{Residuals}
One feature of \Rfunction{triResi} not mentioned in
Section~\ref{sec:standardAssesingModelFit} is the option to turn off
the standardization.  The model accounts for an increase in the
variance of incremental payments as development time progresses by
allowing a scale parameter to vary with development time.  By default,
\Rfunction{triResi} also accounts for this by standardizing all the
residuals to have a standard deviation of one.  Turning off this
feature (via the argument \Robject{standardize} can lead insight into
this process.

The standardized residuals for the change point model are displayed by
development time in Figure~\ref{fig:breakResiDevYearStandardized}.
Figure~\ref{fig:breakResiDevYearUnStandardized} shows the residuals
without this standardization.

\begin{figure}[h]
  \centering

<<breakResiDevYearStandardized, fig=T, height=7, width=14>>=
triResi(break.model.output, timeAxis='dy')

@
\caption{(Standardized) Residuals by development year.}
\label{fig:breakResiDevYearStandardized}
\end{figure}

\begin{figure}[h]
  \centering

<<breakResiDevYearUnStandardized, fig=T, height=7, width=14>>=
triResi(break.model.output, standardize=FALSE, timeAxis='dy')

@
\caption{(Unstandardized) Residuals by development year.}
\label{fig:breakResiDevYearUnStandardized}
\end{figure}

\paragraph{Comparison of Cumulative Payments}
As previously mentioned, the loss triangle used to illustrate the
change point model has an un-ignorable number of zero incremental
payments.  Figure~\ref{fig:breakfinalCumulativeDiff} uses the function
\Rfunction{finalCumulativeDiff} to examine the impact of treating
these values as missing.

\begin{figure}[h]
  \centering

<<breakfinalCumulativeDiff, fig=T, height=7, width=14>>=
finalCumulativeDiff(break.model.output)

@
\caption{Difference in Final Observed Cumulative Payments.}
\label{fig:breakfinalCumulativeDiff}
\end{figure}



\subsubsection{Extracting Inference and Results}
Just as was done for the standard model example, the user will want to
draw inferences from the change point model.  All of the functions
discussed in Section~\ref{sec:standardExtractingInferenceandResults}
are available for this purpose--though some will plot slightly
different charts and return answers in slightly different ways.  In
addition, a few functions are made available to that deal with the
change point.  These functions have no meaning for the standard model
discussed in Section~\ref{sec:UsingtheStandardModelforEstimation}.


\paragraph{Predicted Payments}

Figure~\ref{fig:breakPredictedInc} again uses the function
\Rfunction{predictedPayments} to plot the predicted incremental
payments vs the observed incremental payments. The impact of treating
incremental payments of zero as missing values is most noticeable in
this chart.

\begin{figure}[h]
  \centering

<<breakPredictedInc, fig=T, height=7, width=14>>=
predictedPayments(break.model.output,
                  type='incremental',
                  logScale=TRUE)
@
\caption{Predicted Incremental Payments.}
\label{fig:breakPredictedInc}
\end{figure}



\paragraph{Consumption Path}
Figure~\ref{fig:breakConsumptionPath} plots the consumption path for
the change point model again using the function
\Rfunction{consumptionPath}.  Notice that now two consumption paths
are plotted -- one for the pre-break path and one for the post-break
path.  Both the pre and post break paths are normalized to an
exposure year level equal to the first exposure year.

\begin{figure}[h]
  \centering

<<breakConsumptionPath, fig=T, height=7, width=14>>=
consumptionPath(break.model.output)


@
\caption{Consumption Path.}
\label{fig:breakConsumptionPath}
\end{figure}

\paragraph{Knots in the Consumption Path}
Figure~\ref{fig:breakNumberOfKnots} displays the posterior number of
knots for the change point model example, again using the function
\Rfunction{numberOfKnots}.  Notice that both the number of knots in
the pre-break consumption path and the post-break consumption path are
plotted.

\begin{figure}[h]
  \centering

<<breakNumberOfKnots, fig=T, height=7, width=14>>=
numberOfKnots(break.model.output)


@
\caption{Number of Knots.}
\label{fig:breakNumberOfKnots}
\end{figure}

\paragraph{Rate of Decay}
Figure~\ref{fig:breakRateOfDecay} uses the function
\Rfunction{rateOfDecay} to plot the rate of decay from one development
year to the next for both the pre and post break regimes.  This can be
useful in assessing the impact of changes in the environment effecting
loss development.

\begin{figure}[h]
  \centering

<<breakRateOfDecay, fig=T, height=7, width=14>>=
rateOfDecay(break.model.output)


@
\caption{Rate Of Decay.}
\label{fig:breakRateOfDecay}
\end{figure}

\paragraph{Calendar Year Effect}
Figure~\ref{fig:breakCalendarYearEffect} uses the function
\Rfunction{calendarYearEffect} to plot the calendar year effect for
the change point model.  By default, \Rfunction{calendarYearEffect}
will plot the calendar year effect for all (observed and projected)
incremental payments.  Setting the argument \Robject{restrictedSize}
to TRUE will only plot the calendar year effect for the observed
incremental payments and the projected incremental payments needed to
``square'' the triangle.  This feature can be useful for insurance
lines with log tails.

\begin{figure}[h]
  \centering

<<breakCalendarYearEffect, fig=T, height=7, width=14>>=
calendarYearEffect(break.model.output)


@
\caption{Calendar Year Effect.}
\label{fig:breakCalendarYearEffect}
\end{figure}

Figure~\ref{fig:breakCalendarYearEffectErrors} shows chart resulting
from calling the function \Rfunction{calendarYearEffectErrors}.

\paragraph{Autocorrelation in Calendar Year Effect}
The autocorrelation exhibited in
Figure~\ref{fig:breakCalendarYearEffectErrors} is too strong to
ignore.  As such,
Figure~\ref{fig:breakCalendarYearEffectErrorsWithAR1} illustrates the
use of \Rfunction{makeBreakAnnualInput}'s argument
\Robject{use.ar1.in.calendar.year}.

\begin{figure}[h]
  \centering

<<breakCalendarYearEffectErrors, fig=T, height=7, width=14>>=
calendarYearEffectErrors(break.model.output)


@
\caption{Calendar Year Effect Errors (Without AR1).}
\label{fig:breakCalendarYearEffectErrors}
\end{figure}

\begin{figure}[h]
  \centering
<<breakCalendarYearEffectErrorsAR1WithAR1, fig=T, height=7, width=14>>=

break.model.input.w.ar1 <- makeBreakAnnualInput(cumulative.payments = CumulativeAutoBodilyInjuryTriangle,
                                                stoch.inflation.weight = 1,
                                                non.stoch.inflation.weight = 0,
                                                stoch.inflation.rate = MCPI.rate,
                                                first.year.in.new.regime = c(1986, 1987),
                                                priors.for.first.year.in.new.regime=c(2,1),
                                                exp.year.type = 'ay',
                                                extra.dev.years = 5,
                                                use.skew.t = TRUE,
                                                bound.for.skewness.parameter=5,
                                                use.ar1.in.calendar.year = TRUE)
break.model.output.w.ar1 <- runLossDevModel(break.model.input.w.ar1,
                                            burnIn=30.0E+3,
                                            sampleSize=40.0E+3,
                                            thin=10)
calendarYearEffectErrors(break.model.output.w.ar1)

@
\caption{Calendar Year Effect Errors (With AR1).}
\label{fig:breakCalendarYearEffectErrorsWithAR1}
\end{figure}

Setting \Robject{use.ar1.in.calendar.year} to TRUE enables the use of
an additional function \Rfunction{autoregressiveParameter}.  This
function will plot the autoregressive parameter associated with the
calendar year effect.  Figure~\ref{fig:breakAutoregressiveParameter}
illustrates the use of this function.

\begin{figure}[h]
  \centering
<<breakAutoregressiveParameter, fig=T, height=7, width=14>>=

autoregressiveParameter(break.model.output.w.ar1)
@

<<cleanUpBreakAR1,echo=FALSE>>=
rm(break.model.output.w.ar1, break.model.input.w.ar1)
@

@
\caption{Calendar Year Effect Autoregressive Parameter.}

\label{fig:breakAutoregressiveParameter}
\end{figure}

\paragraph{Skewness Parameter}
Figure~\ref{fig:breakSkew} displays the skewness parameter for the
change point model example by using the function
\Rfunction{skewnessParemeter}.  The result of setting
\Robject{bound.for.skewness.parameter} to 5 is somewhat visible.

\begin{figure}[h]
  \centering

<<breakSkew, fig=T, height=7, width=14>>=
skewnessParameter(break.model.output)


@
\caption{Skewness Parameter.}
\label{fig:breakSkew}
\end{figure}


\paragraph{First Year in New Regime}
The posterior for the first year in which the post-break consumption
path applies can be obtained via the function
\Rfunction{firstYearInNewRegime}. Figure~\ref{fig:breakFirstYearInNewRegime}
shows the posterior (and prior) for the first year in the new regime
in the specified example.  Note how the choice of the argument
\Robject{priors.for.first.year.in.new.regime} to
\Rfunction{makeBreakAnnualInput} has affected the prior.


\begin{figure}[h]
  \centering

<<breakFirstYearInNewRegime, fig=T, height=7, width=14>>=
firstYearInNewRegime(break.model.output)


@
\caption{First Year in New Regime.}
\label{fig:breakFirstYearInNewRegime}
\end{figure}

\section{Accounting for Incremental Payments of Zero}
\label{sec:accoutingForZeros}
As mentioned in Section~\ref{sec:breakLoadingtheData} and illustrated
in Figure~\ref{fig:breakPredictedInc}, the triangle used as an example
for the break model contains many incremental payments of zero which,
if ignored, would cause the predicted losses to be overestimated.

\lossDev{} provides a means to account for these zero payments.  This
is done by estimating a secondary auxiliary model to determine the
probably that a payment will be greater than zero.  Predicted payments
are then weighted by this probability.

\subsection{Estimating the Auxiliary Model}
To account for zero payments, the function
\Rfunction{accountForZeroPayments} is called with the first argument
being an object returned from a call to \Rfunction{runLossDevModel}.
This function will then return another object which, when called by
certain functions already mentioned, will incorporate the probability
that any particular payment is zero into the calculation.
<<accountForZeros>>=
break.model.output.w.zeros <- accountForZeroPayments(break.model.output)
@

\subsection{Assessing Convergence of the Auxiliary Model}
The MCMC run used to estimate the auxiliary model must also be checked
for convergence.  \lossDev{} provides the function
\Rfunction{gompertzParameters} to this end.

The auxiliary model uses a two parameter gompertz function to model
the zero incremental payments.  Which of these parameters is plotted
by \Rfunction{gompertzParameters} is determined by the argument
\Robject{parameter}.

Figure~\ref{fig:zeroPaymentsScale} plots the parameter which
determines the steepness of the curve and is obtained by setting
\Robject{parameter} equal to ``scale.''


\begin{figure}[h]
  \centering

<<zeroPaymentsScale, fig=T, height=7, width=14>>=
gompertzParameters(break.model.output.w.zeros, parameter='scale')


@
\caption{Gompertz Scale Parameter.}
\label{fig:zeroPaymentsScale}
\end{figure}


Figure~\ref{fig:zeroPayments50505} plots the
parameter which determines the point in development time at which the
curve assigns equal probability to payments being zero and payments
being greater than zero and is obtained by setting \Robject{parameter}
equal to ``fifty.fifty.''

\begin{figure}[h]
  \centering

<<zeroPayments5050, fig=T, height=7, width=14>>=
gompertzParameters(break.model.output.w.zeros, parameter='fifty.fifty')


@
\caption{Gompertz Location Parameter.}
\label{fig:zeroPayments50505}
\end{figure}


\subsection{Assessing Fit of the Auxiliary Model}
One can plot the observed empirical probabilities of payments being
greater than zero against the predicted (and projected) probabilities.
This is done with the function \Rfunction{probablityOfPayment}.
Figure~\ref{fig:zeroPaymentsCurve} plot this chart.

\begin{figure}[h]
  \centering

<<zeroPaymentsCurve, fig=T, height=7, width=14>>=
probablityOfPayment(break.model.output.w.zeros)


@
\caption{Probability of Non-Zero Payment.}
\label{fig:zeroPaymentsCurve}
\end{figure}

\subsection{Incorporating the Probability of Non-Zero Payment}
Once the auxiliary model has been estimated and its output verified.
The functions \Rfunction{predictedPayments},
\Rfunction{finalCumulativeDiff}, and \Rfunction{tailFactor} will
incorporate this information into their calculations.

Figure~\ref{fig:breakPredictedIncWithZeros} displays the predicted
incremental payments after accounting for the probability that they may
be zero.  This should be compared with
Figure~\ref{fig:breakPredictedInc} which does not account for the
probability that payments may be zero.

\begin{figure}[h]
  \centering

<<breakPredictedIncWithZeros, fig=T, height=7, width=14>>=
predictedPayments(break.model.output.w.zeros,
                  type='incremental',
                  logScale=TRUE)
@
\caption{Predicted Incremental Payments (Accounting for Zero Payments).}
\label{fig:breakPredictedIncWithZeros}
\end{figure}





\end{document}
